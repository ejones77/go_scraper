# go_scraper

Submitted assignment for Northwestern MSDS 431

## Overview

This program performs web crawling and web scraping on a series of Wikipedia articles using Colly and Goquery. The output is a structured JSON file of article objects. 

The JSON file can be generated by cloning the repository and running ./wiki_scraper.exe within the repo's main directory

## Features
- Each article has a title, sections, and references. Each section has paragraphs with their associated text and hyperlinks.
- Within each section, list elements are treated as paragraphs and processed the same way.
- Links are detected via a search for `href` attributes within `<a>` tags.
- Links are also their own structure with the reference text and the url. 
- Sometimes the URL points to a citation, such as `#cite_ref-15`, these relate to the `id` in the articles `references` field.
- References have a dedicated section in Wikipedia articles. The text required Goquery's methods of removing CSS style from the initial extraction of the text element.
- Goquery also makes it easier to keep your extraction within a nested element, using `selections` in the place of `elements`. 

## Example Article Object
```
{
  "Title": "Example Article",
  "Sections": [
    {
      "Title": "Introduction",
      "Paragraphs": [
        {
          "Text": "This is the first paragraph of the introduction.",
          "Links": [
            {
              "Text": "Example Link",
              "URL": "https://example.com"
            }
          ]
        },
        {
          "Text": "This is the second paragraph of the introduction.",
          "Links": []
        }
      ]
    },
    {
      "Title": "Main Section",
      "Paragraphs": [
        {
          "Text": "This is the first paragraph of the main section.",
          "Links": []
        }
      ]
    }
  ],
  "References": [
    {
      "Id": "cite_note-6",
      "Text": "This is the first reference.",
      "Links": [
        {
          "Text": "Reference Link",
          "URL": "https://reference.com"
        }
      ]
    }
  ]
}
```

## Comparsion with Python
- The python program using scrapy to extract text from the same set of articles takes about 23 seconds, while this Go program took 1.3 seconds, that's a very significant improvement in speed.
- The writing to JSON lines also improved speed by about one second overall.
- The JSON data provides the same benefits from extracting text in isolation, while unlocking a deeper analysis into the network of hyperlinks and citations within a specific topic area.